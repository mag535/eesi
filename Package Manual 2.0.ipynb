{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using MoC (Matrix of Confusion) \n",
    "\n",
    "\n",
    "## Quick Start\n",
    "\n",
    "    Create a Misc object, then use the function main(). \n",
    "    \n",
    "    Arguments:\n",
    "        - Input: the name of the ground truth profile file\n",
    "        - Output: the excel file name, a .xlsx of six sheets: True Positives, False Negatives, False Positives, True \n",
    "            Negatives, Precision, Recall of each tool\n",
    "        - (optional) input directory of all profiles, including the ground truth; <Default: Directory of Package Manual>\n",
    "        - (optional) the output directory; <Default: Directory of Package Manual>\n",
    "        - (optional) \"yes\" if you want individual .csv files for each tool's predicted profile; <Default: \"no\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Added as matrix pred.profile\n",
      "\n",
      "Added as matrix pred2.profile\n",
      "\n",
      "Added as matrix pred3.profile\n",
      "\n",
      "Saved as 'TaxaPerformanceMetrics_byTool.xlsx'\n"
     ]
    }
   ],
   "source": [
    "from MoC.precall import Misc\n",
    "\n",
    "Quick = Misc()\n",
    "\n",
    "Quick.main(\"truth.profile\", \"TaxaPerformanceMetrics_byTool\", \"C:\\\\*\\\\*\\\\*\\\\MoC\\\\Test Files\\\\\", \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up:\n",
    "\n",
    "    To set up a python file for MoC, first import the modules in the package.\n",
    "    Then create objects to use each module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MoC.profile_parser import Parser\n",
    "from MoC.comparator import Comparator\n",
    "from MoC.confusion_matrix import Confusion\n",
    "from MoC.precall import Misc\n",
    "\n",
    "myParser = Parser()\n",
    "myComparer = Comparator()\n",
    "myConfusion = Confusion(\"truth\", \"pred\")\n",
    "myMisc = Misc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How they work\n",
    "\n",
    "    The main purpose of this module is to calculate each Tax ID's confusion matrix and save that and other information into a .csv file.\n",
    "\n",
    "    Each module does a specific step in that process\n",
    "\n",
    "### Parse\n",
    "\n",
    "    Parse separates the relevant information for each Tax ID (ie. rank, abundance, etc.) into dictionaries. Both functions parse_data() and main() return a dictionary of dictionaries variable, but main() does a little more with it.\n",
    "\n",
    "    The returned variable looks like this:\n",
    "\n",
    "    {Sample Number : dict}\n",
    "                   - {Rank : dict}\n",
    "                           - {Tax ID : Abundance}\n",
    "\n",
    "    There is an alternative parsing format that can be used to get other information about the Tax ID (name and rank), which returns a dictionary of dictionaries variable that looks like this:\n",
    "\n",
    "    {Sample Number : dict}\n",
    "                  - {Tax ID : list}\n",
    "                            - [rank, name]\n",
    "\n",
    "    The functions that contribute to main() and parse_data() can be used individually as shown below\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### main(self, f, t=0)\n",
    "\n",
    "    This function calls parse_data(), divide_content(), and get_file() to create and return a dictionary where sample number is the key and a dictionary of {Rank : {Tax ID : Abundance}} is the value.\n",
    "    \n",
    "    The variable t is optional and the default is zero. Passing one for t instead of zero tells the program to use the alternative parsing format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_1 = myParser.main(\"pred\")\n",
    "sample_2 = myParser.main(\"pred2\")\n",
    "\n",
    "sample_1_alt = myParser.main(\"pred\", 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### print_samples(self, samples, t=0)\n",
    "\n",
    "    This function prints the contents of the dictionary samples in a viewable way.\n",
    "\n",
    "    The variable t defaults to zero, printing in the format of the default sample format. If t=1, it prints in the alternative format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~DEFAULT~\n",
      "Sample Number: 0\n",
      "\tRank: rank1\n",
      "\t\t1 - 100.0\n",
      "\tRank: rank2\n",
      "\t\t3 - 97.0\n",
      "\t\t4 - 2.0\n",
      "\t\t7 - 1.0\n",
      "Sample Number: 1\n",
      "\tRank: rank1\n",
      "\t\t1 - 100.0\n",
      "\tRank: rank2\n",
      "\t\t3 - 15.0\n",
      "\t\t5 - 85.0\n",
      "~ALTERNATIVE~\n",
      "Sample Number: 0\n",
      "\tTax ID: 1\n",
      "\t\tRank - rank1, Name - bac\n",
      "\tTax ID: 3\n",
      "\t\tRank - rank2, Name - bac|bac1\n",
      "\tTax ID: 4\n",
      "\t\tRank - rank2, Name - bac|bac2\n",
      "\tTax ID: 7\n",
      "\t\tRank - rank2, Name - bac|bac4\n",
      "Sample Number: 1\n",
      "\tTax ID: 1\n",
      "\t\tRank - rank1, Name - bac\n",
      "\tTax ID: 3\n",
      "\t\tRank - rank2, Name - bac|bac1\n",
      "\tTax ID: 5\n",
      "\t\tRank - rank2, Name - bac|bac3\n"
     ]
    }
   ],
   "source": [
    "print(\"~DEFAULT~\")\n",
    "myParser.print_samples(sample_1)\n",
    "print(\"~ALTERNATIVE~\")\n",
    "myParser.print_samples(sample_1_alt, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparator\n",
    "\n",
    "    Comparator compares two sample dictionaries to find the common Tax IDs in each sample and to combine the Tax IDs in each sample into a new dictionary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### main(self, files, t=0)\n",
    "\n",
    "    The main() function takes in a string (files) of two profile names (without the '.profile' part) separated by a space. It also accepts an optional argument t that is used when the function calls on Parser.main().\n",
    "    \n",
    "    This function returns two dictionaries where sample number is the key and a set is the value. The sets for the two dictionaries contain all the Tax IDs from both samples, excluding repeats, or the Tax IDs both samples had in common, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: {1, 3, 4}, 1: {1, 3, 5}}\n",
      "{0: {1, 2, 3, 4, 6, 7}, 1: {1, 3, 5}}\n"
     ]
    }
   ],
   "source": [
    "common_1_2, combined_1_2 = myComparer.main(\"truth pred\")\n",
    "print(common_1_2)\n",
    "print(combined_1_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### save_tax_ID(self, samples)\n",
    "\n",
    "    This function iterates over a samples dictionary and uses get_tax_ID() to create and return a dictionary where sample number is the key and a set of Tax IDs from that sample is the value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: {1, 3, 4, 7}, 1: {1, 3, 5}}\n",
      "{0: {1, 3, 4}, 1: {1, 2, 5}}\n"
     ]
    }
   ],
   "source": [
    "sample_tax_ID_1 = myComparer.save_tax_ID(sample_1)\n",
    "sample_tax_ID_2 = myComparer.save_tax_ID(sample_2)\n",
    "print(sample_tax_ID_1)\n",
    "print(sample_tax_ID_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### common_tax_ID(self, tax_id1, tax_id_2)\n",
    "\n",
    "    This function creates and returns a dictionary where sample number is the key and a set containing the common Tax IDs between two sample files is the value. It iterates over a samples dictionary and calls _common_tax_ID() to save each set under a sample number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: {1, 3, 4}, 1: {1, 5}}\n"
     ]
    }
   ],
   "source": [
    "common_dict_1_2 = myComparer.common_tax_ID(sample_tax_ID_2, sample_tax_ID_1)\n",
    "print(common_dict_1_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### combine_tax_ID(self, tax_id_1, tax_id_2)\n",
    "\n",
    "    This function creates and returns a dictionary where sample number is the key and a set containing the Tax IDs from both sample dictionaries is the value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: {1, 3, 4, 7}, 1: {1, 2, 3, 5}}\n"
     ]
    }
   ],
   "source": [
    "combined_dict_1_2 = myComparer.combine_tax_ID(sample_tax_ID_2, sample_tax_ID_1)\n",
    "print(combined_dict_1_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion\n",
    "\n",
    "    Confusion uses both Comparator and Parser to create a confusion matrix for every Tax ID in each sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### \\__init__(self, tru, fn)\n",
    "\n",
    "    The constructor for Confusion objects is a little different since it takes two arguments, one for the name of the truth file and one for the name of the predicted file (excluding the '.profile' part)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Confu = Confusion(\"truth\", \"pred\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### get_file_name(self) and get_truth(self)\n",
    "\n",
    "    These functions return a string containing the name of the predicted and truth files respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Truth: truth \n",
      "Predicted: pred\n"
     ]
    }
   ],
   "source": [
    "print(\"Truth:\", Confu.get_truth(), '\\nPredicted:', Confu.get_file_name())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### set_file_name(self, tru) and set_truth(self, fn)\n",
    "\n",
    "    These two functions allow you to change the ground truth or predicted file whenever you need to. It also makes it so that you only need one Confusion object for multiple predicted files or even multiple truth files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Truth: pred \n",
      "Predicted: pred2\n"
     ]
    }
   ],
   "source": [
    "Confu.set_file_name(\"pred2\")\n",
    "Confu.set_truth(\"pred\")\n",
    "print(\"Truth:\", Confu.get_truth(), '\\nPredicted:', Confu.get_file_name())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### main(self, csv=\"yes\", t=0)\n",
    "\n",
    "    This function uses Comparer and Parser and internal functions to create a confusion matrix for the predicted file, then save that data as a .csv file. The automatic name for that .csv file is the truth and predicted file names joined by two hyphens (ie. Truth='truth', Predicted='pred', .csv name='truth--pred.csv').\n",
    "    \n",
    "    It also returns the confusion matrix it created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_p_matrix = Confu.main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### check_matrix_error(self, matrix)\n",
    "\n",
    "    This a supplementary function that checks to make sure the sum of the numbers in the confusion matrix equal the total number of samples in the ground truth file for each Tax ID. It then returns a list of the Tax IDs with confusion matrices that are over and under that number respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([], [])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Confu.check_matrix_error(t_p_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Misc\n",
    "\n",
    "    Misc is mainly for finding the confusion matrices of multiple profiles at once and creating an .xlsx file to display the confusion matrix values for each predicted file and the ground truth on separate sheets. It also uses the Precall class to calculate and add a sheet for precision and recall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### main(self, names, file_path=\"\", excel_name=\"Default_excel_name\", csv=\"no\")\n",
    "\n",
    "    This function takes in a list of the names of each profile being evaluated, a string to determine whether or not individual file data should be saved to .csv files, and another string for the .xlsx file's name. \n",
    "        For the names list, the name of the ground truth file should come first, followed by the predicted file(s). The ground truth will also have its confusion matrices, precision, and recall calculated and saved to the final .xlsx file. \n",
    "            For the csv string, pass in \"yes\" to save each files' confusion matrices to individual .csv files. The .csv file names will be <Truth>--<Predicted>.csv (the csv string is not case sensitive). Pass in \"no\" to skip this step. Passing in any other string will also skip that step. The default value for the csv string is \"no\", so the argument is optional.\n",
    "                For the excel_name string, file naming rules apply. Otherwise, it can be anything. The default value is \"Default_excel_name\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Added as matrix truth\n",
      "\n",
      "Added as matrix pred\n",
      "\n",
      "Added as matrix pred2\n",
      "\n",
      "Added as matrix pred3\n",
      "\n",
      "Saved as 'C:\\Users\\milkg\\Documents\\Trail_Run_2.xlsx'\n"
     ]
    }
   ],
   "source": [
    "myMisc.main([\"truth\", \"pred\", \"pred2\", \"pred3\"], \"C:\\\\Users\\\\\", \"Trail_Run_1\", \"yes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
